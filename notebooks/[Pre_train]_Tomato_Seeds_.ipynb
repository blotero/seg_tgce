{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgBp_sHPadNI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install roboflow\n",
        "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.image_segmentation.git >> /tmp/null\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import h5py\n",
        "import time\n",
        "import shutil\n",
        "import random\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from enum import auto, Enum\n",
        "from datetime import datetime\n",
        "from functools import partial\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import Loss\n",
        "from tensorflow.keras.metrics import Metric\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.layers import Layer, Activation\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Concatenate\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Libreria GCPDS\n",
        "from gcpds.image_segmentation.datasets.segmentation import OxfordIiitPet\n",
        "from gcpds.image_segmentation.visualizations import plot_contour\n",
        "from gcpds.image_segmentation.models import unet_baseline\n",
        "\n",
        "# Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.style import available\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "\n",
        "# Custom activation function\n",
        "from keras.layers import Activation\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lrG2NPOadNK"
      },
      "source": [
        "## Retrieve dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brsYU62madNK",
        "outputId": "b7f8f205-5be6-45f2-e6a1-ba07b865058a"
      },
      "outputs": [],
      "source": [
        "rf = Roboflow(api_key=\"3ioUIbqERJ2jEWElELQN\")\n",
        "project = rf.workspace(\"gcpds-tm2ae\").project(\"seed-detection-2\")\n",
        "dataset = project.version(1).download(\"png-mask-semantic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7fuXvFTadNN"
      },
      "source": [
        "## Conversión del dataset a tensores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9dgLeovadNN"
      },
      "outputs": [],
      "source": [
        "def decode_img(img, target_size):\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    return tf.image.resize(img, target_size) / 255.0\n",
        "\n",
        "def decode_mask(mask, target_size):\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    return tf.image.resize(mask, target_size) / 255.0\n",
        "\n",
        "def process_path(image_path, mask_path, target_size):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = decode_img(img, target_size)\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = decode_mask(mask, target_size)\n",
        "    return img, mask\n",
        "\n",
        "def load_dataset(data_dir, target_size, batch_size):\n",
        "    image_files = [f for f in os.listdir(data_dir) if f.endswith(\".jpg\")]\n",
        "    image_paths = [os.path.join(data_dir, img_file) for img_file in image_files]\n",
        "    mask_paths = [path.replace(\".jpg\", \"_mask.png\") for path in image_paths]\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
        "    dataset = dataset.map(lambda x, y: process_path(x, y, target_size),\n",
        "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.cache().batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th7O_45OadNO",
        "outputId": "b76df001-7492-43b0-82a3-d20d36933974"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "dataset_train = load_dataset(data_dir=\"./Seed-Detection-2-1/train\", target_size=(256,256), batch_size=32)\n",
        "dataset_test = load_dataset(data_dir=\"./Seed-Detection-2-1/test\", target_size=(256,256), batch_size=32)\n",
        "dataset_valid = load_dataset(data_dir=\"./Seed-Detection-2-1/valid\", target_size=(256,256), batch_size=32)\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"El tiempo de ejecución de la conversión del dataset a tensores fue de {elapsed_time:.3f} segundos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY3DUusiadNP"
      },
      "source": [
        "### Train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "tXidJFzQadNP",
        "outputId": "1110bb7b-1745-4303-f602-628b0ae73ebf"
      },
      "outputs": [],
      "source": [
        "for img, mask in dataset_train.take(1):\n",
        "  plt.imshow(img[0])\n",
        "  plt.show()\n",
        "  plt.imshow(mask[0])\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfv9nJqmadNR"
      },
      "source": [
        "## Train segmentation UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mYqIu007p0w"
      },
      "outputs": [],
      "source": [
        "@keras.saving.register_keras_serializable(package=\"MyLayers\")\n",
        "class DiceCoefficient(Loss):\n",
        "    def __init__(self, smooth=1., target_class= None, name='DiceCoefficient', **kwargs):\n",
        "        self.smooth = smooth\n",
        "        self.target_class = target_class\n",
        "        super().__init__(name=name,**kwargs)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        intersection = K.sum(y_true * y_pred, axis=[1,2])\n",
        "        union = K.sum(y_true,axis=[1,2]) + K.sum(y_pred,axis=[1,2])\n",
        "        dice_coef = -(2. * intersection + self.smooth) /(union + self.smooth)\n",
        "\n",
        "        if self.target_class != None:\n",
        "            dice_coef = tf.gather(dice_coef,\n",
        "                                  self.target_class, axis=1)\n",
        "        else:\n",
        "            dice_coef = K.mean(dice_coef,axis=-1)\n",
        "\n",
        "        return dice_coef\n",
        "\n",
        "    def get_config(self,):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"smooth\": self.smooth,\n",
        "                \"target_class\":self.target_class}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c_JdgH07Xza",
        "outputId": "b1e3b5b7-512d-41df-e9a4-3509d900bd6e"
      },
      "outputs": [],
      "source": [
        "TARGET_SHAPE = (256,256)\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "model = unet_baseline(input_shape= TARGET_SHAPE + (3,), out_channels=1)\n",
        "model.compile(\n",
        "    loss=DiceCoefficient(),\n",
        "    optimizer=\"adam\",\n",
        "    )\n",
        "model.summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnvFanp-7y5D",
        "outputId": "aaa9b0c3-ac0d-4328-9efc-48222ff9a851"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    dataset_train,\n",
        "    validation_data=dataset_valid,\n",
        "    epochs=NUM_EPOCHS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJFjesehuopA",
        "outputId": "65f0ee58-9955-428d-d5cf-9f66acffa748"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "meB8toW_-7pA",
        "outputId": "54ac9650-dd72-461c-8e31-8c1cf9ecb32b"
      },
      "outputs": [],
      "source": [
        "destination_path = \"/content/drive/MyDrive/models/Tomato Seeds\"\n",
        "\n",
        "model_save_path = os.path.join(destination_path ,\"tomato_seed_base_model.keras\")\n",
        "model.save(filepath=model_save_path)\n",
        "model_save_path"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4371669,
          "sourceId": 7506556,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30635,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "jupyter_env",
      "language": "python",
      "name": "jupyter_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
