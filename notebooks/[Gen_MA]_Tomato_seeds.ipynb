{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMu5dfgQ82BR",
        "outputId": "6a0ea368-3de6-4ec9-d272-829b04499e27"
      },
      "outputs": [],
      "source": [
        "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.image_segmentation.git >> /tmp/null\n",
        "!pip install roboflow >> /tmp/null\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL783b3p9B8p"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "import random\n",
        "import warnings\n",
        "import cv2\n",
        "\n",
        "from functools import partial\n",
        "from enum import auto, Enum\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from gcpds.image_segmentation.datasets.segmentation import OxfordIiitPet\n",
        "from gcpds.image_segmentation.visualizations import plot_contour\n",
        "from gcpds.image_segmentation.models import unet_baseline\n",
        "# from gcpds.image_segmentation.losses import DiceCoefficient\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "\n",
        "from matplotlib.style import available\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import Loss\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "import gdown\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3rUBbSh-_F9"
      },
      "source": [
        "## Fetch pre trained UNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8i85xM0_Dek",
        "outputId": "0e06d8c6-3e9f-4b24-cf05-0fa180d5ca1a"
      },
      "outputs": [],
      "source": [
        "model_folder_id = \"1QnV6GLaH6ciuyqsgNHKIqTi2JwsAlWbE\"\n",
        "\n",
        "\n",
        "gdown.download_folder(id=model_folder_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UNTpPdzD7yP"
      },
      "source": [
        "## Fetch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwolDaYv9DZU",
        "outputId": "9bed578d-a4c6-44ce-95b1-ca1e41f0e0ab"
      },
      "outputs": [],
      "source": [
        "rf = Roboflow(api_key=\"3ioUIbqERJ2jEWElELQN\")\n",
        "project = rf.workspace(\"gcpds-tm2ae\").project(\"seed-detection-2\")\n",
        "dataset = project.version(1).download(\"png-mask-semantic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEllM2k-9NW5"
      },
      "outputs": [],
      "source": [
        "def decode_img(img, target_size):\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    return tf.image.resize(img, target_size) / 255.0\n",
        "\n",
        "def decode_mask(mask, target_size):\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    return tf.image.resize(mask, target_size) / 255.0\n",
        "\n",
        "def process_path(image_path, mask_path, target_size):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = decode_img(img, target_size)\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = decode_mask(mask, target_size)\n",
        "    return img, mask\n",
        "\n",
        "def load_dataset(data_dir, target_size):\n",
        "    image_files = [f for f in os.listdir(data_dir) if f.endswith(\".jpg\")]\n",
        "    image_paths = [os.path.join(data_dir, img_file) for img_file in image_files]\n",
        "    mask_paths = [path.replace(\".jpg\", \"_mask.png\") for path in image_paths]\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
        "    dataset = dataset.map(lambda x, y: process_path(x, y, target_size),\n",
        "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3eRsbLw-m3c"
      },
      "source": [
        "## Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbQmYVEw9O0d"
      },
      "outputs": [],
      "source": [
        "train_dataset = load_dataset(data_dir=\"./Seed-Detection-2-1/train\", target_size=(256,256) )\n",
        "test_dataset = load_dataset(data_dir=\"./Seed-Detection-2-1/test\", target_size=(256,256)  )\n",
        "val_dataset = load_dataset(data_dir=\"./Seed-Detection-2-1/valid\", target_size=(256,256)  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJg0-pEi-jM8",
        "outputId": "fe1eabf7-17a5-4aad-b18a-2ecfbd281097"
      },
      "outputs": [],
      "source": [
        "model_extension = \"keras\"\n",
        "folder_name = \"/content/Tomado Seeds\"\n",
        "paths = []\n",
        "\n",
        "for file in os.listdir(folder_name):\n",
        "  if file.endswith(model_extension):\n",
        "    paths.append(file)\n",
        "\n",
        "model_path = os.path.join(folder_name, paths[0])\n",
        "print(f\"Loading {model_path}...\")\n",
        "model  = tf.keras.models.load_model(model_path, compile = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdjllGuXBQD5",
        "outputId": "72aa46a4-5ce2-478a-9b15-7cb95fd33b20"
      },
      "outputs": [],
      "source": [
        "model.input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cInAycklABg6",
        "outputId": "a301fc7c-41e7-4ba8-8169-bc4be23a0887"
      },
      "outputs": [],
      "source": [
        "def find_last_encoder_conv_layer(model):\n",
        "  last_conv_encoder_layer = 0\n",
        "  for i,layer in enumerate(model.layers):\n",
        "    if (isinstance(layer, keras.layers.Conv2D)):\n",
        "      last_conv_encoder_layer = i\n",
        "    if (isinstance(layer, keras.layers.UpSampling2D)):\n",
        "      break\n",
        "  return last_conv_encoder_layer\n",
        "\n",
        "last_conv_encoder_layer = find_last_encoder_conv_layer(model)\n",
        "last_conv_encoder_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sFWFSZ6AyJk"
      },
      "outputs": [],
      "source": [
        "def compute_snr(signal:float, noise_std:float)->float:\n",
        "  return  10 * np.log10(np.mean(signal ** 2)  / noise_std ** 2)\n",
        "\n",
        "class SnrType(Enum):\n",
        "  log = 0\n",
        "  linear = 1\n",
        "\n",
        "\n",
        "def add_noise_to_layer_weights(model, layer, noise_snr, snr_type: SnrType = SnrType.log, verbose = 0):\n",
        "  layer_weights = model.layers[layer].get_weights()\n",
        "\n",
        "  sig_power = np.mean(layer_weights[0] ** 2)\n",
        "\n",
        "\n",
        "  if snr_type == SnrType.log:\n",
        "    noise_power = sig_power / (10 ** (noise_snr / 10) )\n",
        "  elif snr_type == SnrType.linear:\n",
        "    noise_power = sig_power / noise_snr\n",
        "\n",
        "  noise_std = noise_power ** ( 1 / 2)\n",
        "\n",
        "  snr = compute_snr(layer_weights[0], noise_std)\n",
        "\n",
        "\n",
        "  if verbose > 0 :\n",
        "    print(f\"Adding noise for snr: {noise_snr}\\n\\n\")\n",
        "    print(f\"Signal power: {sig_power}\")\n",
        "    print(f\"Noise power: {noise_power}\\n\\n\")\n",
        "\n",
        "  for i in range(layer_weights[0].shape[0]):\n",
        "    for j in range(layer_weights[0].shape[1]):\n",
        "      layer_weights[0][i][j] += np.random.randn(128,128) * noise_std\n",
        "\n",
        "  model.layers[last_conv_encoder_layer].set_weights(layer_weights)\n",
        "  return snr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTUNYqdSAzjU"
      },
      "outputs": [],
      "source": [
        "values_to_test = [10, 5, 2, 0, -10]\n",
        "\n",
        "\n",
        "def produce_disturbed_models(values_to_test, base_model_path):\n",
        "  snr_values = []\n",
        "  models = []\n",
        "\n",
        "  for value in values_to_test:\n",
        "    model_ = tf.keras.models.load_model(base_model_path, compile = False)\n",
        "    snr = add_noise_to_layer_weights(model_, last_conv_encoder_layer, value)\n",
        "    snr_values.append(snr)\n",
        "    models.append(model_)\n",
        "  return models, snr_values\n",
        "\n",
        "disturbance_models, snr_values = produce_disturbed_models(values_to_test, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR8oCsBFA1Am",
        "outputId": "d64d2cbc-f1f1-4945-8123-0c49a28b9d62"
      },
      "outputs": [],
      "source": [
        "disturbance_models[0].output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0MDDXxXA5SL"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "TARGET_SHAPE = 256, 256\n",
        "ANNOTATORS = 5\n",
        "\n",
        "def disturb_mask(model, image):\n",
        "  return model(image)\n",
        "\n",
        "\n",
        "\n",
        "def mix_channels(mask, num_annotators):\n",
        "  return tf.stack([mask, 1-mask], axis=-2)\n",
        "\n",
        "def add_noisy_annotators(img: EagerTensor, models)->EagerTensor:\n",
        "  return [disturb_mask(model, img) for model in models]\n",
        "\n",
        "\n",
        "\n",
        "def map_dataset_MA(dataset, target_shape, batch_size, num_annotators):\n",
        "\n",
        "    dataset_ = dataset.map(lambda img,mask: (tf.image.resize(img,target_shape), tf.image.resize(mask,target_shape)),\n",
        "                                    num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset_ = dataset_.map(lambda img,mask: (tf.image.resize(img,target_shape), tf.image.resize(mask,target_shape)),\n",
        "                                    num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset_ = dataset_.map(lambda img,mask: (img, add_noisy_annotators(tf.expand_dims(img, 0), disturbance_models)),\n",
        "                           num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    #transpose dataset\n",
        "\n",
        "    dataset_ = dataset_.map(lambda img,mask: (img, tf.squeeze(mask, axis=-1)),\n",
        "                           num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset_ = dataset_.map(lambda img,mask: (img, tf.transpose(mask, [2,3,1,0])),\n",
        "                           num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset_ = dataset_.batch(batch_size)\n",
        "    return dataset_\n",
        "\n",
        "\n",
        "train = map_dataset_MA(train_dataset, TARGET_SHAPE, BATCH_SIZE, ANNOTATORS)\n",
        "val = map_dataset_MA(val_dataset, TARGET_SHAPE, BATCH_SIZE, ANNOTATORS)\n",
        "test = map_dataset_MA(test_dataset, TARGET_SHAPE, BATCH_SIZE, ANNOTATORS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "N_OaK6PTBI8E",
        "outputId": "5f85e886-9dba-41d3-de39-fc4d007d0170"
      },
      "outputs": [],
      "source": [
        "for img,mask in train.take(1):\n",
        "  print(f\"Mask shape: {mask.shape} (batch_size * h * w * k * r)\")\n",
        "  fig, axes = plt.subplots(2,ANNOTATORS)\n",
        "  fig.set_size_inches(16,7)\n",
        "  for i in range(ANNOTATORS):\n",
        "    axes[0][i].imshow(img[0])\n",
        "    axes[1][i].imshow(mask[0,:,:,0,i])\n",
        "    axes[1][i].set_title(f\"Annotation with SNR={values_to_test[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOhxtQjiHuD7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
